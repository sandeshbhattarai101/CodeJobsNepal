{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c67e8630-271b-49b8-b22f-e23913a61162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "80943de7-663a-44f9-993a-f4096283ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.162 Safari/537.36'}\n",
    "\n",
    "\n",
    "# Finding total pages in the website\n",
    "\n",
    "listing_url = 'https://merojob.com/category/it-telecommunication/?page=1'\n",
    "response = requests.get(listing_url, headers = headers)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "pagination = soup.find('ul', class_= 'pagination')\n",
    "\n",
    "if pagination:\n",
    "    # find the tatal page numbers except 'next' or 'previous'\n",
    "    pages = pagination.find_all('li')\n",
    "    page_numbers = []\n",
    "\n",
    "    for page in pages:\n",
    "        try:\n",
    "            num = int(page.text.strip())   \n",
    "            page_numbers.append(num)          \n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    max_page = max(page_numbers) if page_numbers else 1\n",
    "else:\n",
    "    max_page = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1ea48d73-5d94-4e59-95fe-10aec41447d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Job Title': '\\n                        Senior Front-End Developer\\n                        \\n\\n\\n', 'Company Name': '\\nProcess Hub Nepal\\n', 'key': 'value'}\n",
      "{'Job Title': '\\n                        Senior Front-End Developer\\n                        \\n\\n\\n', 'Company Name': '\\nProcess Hub Nepal\\n', 'key': 'value'}\n",
      "{'Job Title': '\\n                        Senior Front-End Developer\\n                        \\n\\n\\n', 'Company Name': '\\nProcess Hub Nepal\\n', 'key': 'value'}\n",
      "{'Job Title': '\\n                        Senior Front-End Developer\\n                        \\n\\n\\n', 'Company Name': '\\nProcess Hub Nepal\\n', 'key': 'value'}\n",
      "{'Job Title': '\\n                        Senior Front-End Developer\\n                        \\n\\n\\n', 'Company Name': '\\nProcess Hub Nepal\\n', 'key': 'value'}\n",
      "{'Job Title': '\\n                        Senior Front-End Developer\\n                        \\n\\n\\n', 'Company Name': '\\nProcess Hub Nepal\\n', 'key': 'value'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "job_list = []\n",
    "basic_list = []\n",
    "\n",
    "#including base url because href only includes page address\n",
    "base_url = \"https://merojob.com\"\n",
    "    \n",
    "# we are not using range(max_page+1) because it will start from 0 by default\n",
    "for i in range(1, (max_page + 1)):\n",
    "    webpage = requests.get('https://merojob.com/category/it-telecommunication/?page={}'.format(i), headers = headers).text\n",
    "    \n",
    "    soup = BeautifulSoup(webpage, 'lxml')\n",
    "\n",
    "    # In website from where data is scraped, jobs are under classname \"job-card\"\n",
    "    #.text is only used on single items so using loop to seperate single item from list\n",
    "    #.strip() is used to remove any trailing whitespaces and namespaces\n",
    "    \n",
    "    job_cards = soup.find_all('h1', class_= 'media-heading')\n",
    "\n",
    "    if not job_cards:\n",
    "        print('No jobs found on this page, stopping.')\n",
    "        break\n",
    "\n",
    "    for job in job_cards:\n",
    "        link_tag = job.find('a', href= True)\n",
    "        if link_tag:\n",
    "            job_url = base_url + link_tag['href']\n",
    "            # print(f\"Visiting: {job_url}\")\n",
    "\n",
    "            job_detail_resp = requests.get(job_url, headers = headers)\n",
    "            job_soup = BeautifulSoup(job_detail_resp.text, 'lxml')\n",
    "        \n",
    "            \n",
    "            if job_soup:\n",
    "                head_info = job_soup.find('div', class_= 'media-body mt-3')\n",
    "\n",
    "                job_title_info = head_info.find_all('h1')\n",
    "\n",
    "                #there are more than one element in head_info so    \n",
    "                for title in job_title_info:\n",
    "                    job_title = title.text\n",
    "\n",
    "                company_name_info = head_info.find_all('a')\n",
    "                \n",
    "                for name in company_name_info:\n",
    "                    company_name = name.text\n",
    "\n",
    "                basic_job_info = job_soup.find('table', class_= 'table')\n",
    "\n",
    "                for row in basic_job_info.find_all('tr'):\n",
    "                    cells = row.find_all(['th', 'td'])\n",
    "                    if cells:\n",
    "                        key = cells[0].text.strip()\n",
    "                        value = cells[2].text.strip().replace('\\n', ' ').strip()                 \n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10332802-b492-4be1-a67e-92cc28f9dc0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
